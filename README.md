# ğŸ“– BookNotes â€” AI-Powered Book Summary Engine

A multi-audience, **citation-grounded** book-notes summarizer powered by **Groq** (Llama 3.3 70B) with **RAG retrieval** via HuggingFace embeddings. Paste your highlights, pick a mode, and get verified summaries where every claim cites its source.

**[Live Demo â†’](https://book-notes-summarizer.vercel.app)** Â· **Completely Free** Â· **Deploy in 2 minutes**

---

## âœ¨ What It Does

Paste book notes or highlights â†’ select a summary mode â†’ get a structured, citation-grounded summary. Every claim links back to the specific highlight that supports it.

### 4 Summary Modes

| Mode | What You Get | Constraints |
|---|---|---|
| â± **1-Minute** | Thesis + key points + conclusion | â‰¤120 words, 3â€“5 items |
| ğŸ”¬ **Technical** | Frameworks, mechanisms, tradeoffs | â‰¤250 words, 4â€“8 items |
| ğŸ§’ **Kid-Friendly** | Simple language with analogies | â‰¤120 words, must include analogy |
| ğŸ’¼ **Interview Prep** | Professional takeaways | Exactly 5 bullets, â‰¤18 words each |

### Key Features

- **Citation Grounding** â€” Every output item cites specific highlights `[H1]`, `[H3]`. Click any citation to see the exact source text.
- **RAG Retrieval** â€” Before generation, mode-specific queries find the most relevant highlights via semantic similarity (HuggingFace embeddings). Only the best evidence is passed to the LLM.
- **Zod Validation** â€” Every response is validated against strict per-mode schemas. Failed responses get auto-repaired (1 retry with error feedback).
- **Strictness Modes** â€” "Strict" allows only directly supported claims. "Balanced" permits mild inference, labeled accordingly.
- **Generate All 4 Modes** â€” One click to generate all modes. Compare them side-by-side.
- **Save Note Sets** â€” Save your notes with a name. Load them later. Run history persists per note set.
- **Eval Dashboard** â€” Track pass rates, citation coverage, word limit compliance, and common failure reasons across all runs.
- **Export** â€” Download as Markdown, copy Notion-ready format, export as JSON, or copy plain text.

---

## ğŸš€ Quick Start

### Prerequisites
- Node.js 18+
- A free Groq API key

### 1. Clone & install

```bash
git clone https://github.com/YOUR_USERNAME/book-notes-summarizer.git
cd book-notes-summarizer
npm install
```

### 2. Add your API keys

```bash
cp .env.example .env.local
```

Edit `.env.local`:

```env
GROQ_API_KEY=gsk_your_groq_key_here
HF_API_TOKEN=hf_your_huggingface_token_here  # optional
```

**Get your free keys:**
- **Groq** (required): [console.groq.com/keys](https://console.groq.com/keys) â€” no credit card, 30 req/min
- **HuggingFace** (optional): [huggingface.co/settings/tokens](https://huggingface.co/settings/tokens) â€” improves RAG quality

### 3. Run

```bash
npm run dev
```

Open [http://localhost:3000](http://localhost:3000)

### 4. Run tests

```bash
npm test
```

---

## ğŸŒ Deploy to Vercel

1. Push to GitHub
2. Go to [vercel.com/new](https://vercel.com/new) â†’ Import your repo
3. Add environment variables:
   - `GROQ_API_KEY` = your Groq key
   - `HF_API_TOKEN` = your HuggingFace token (optional)
4. Click **Deploy** â†’ live in ~60 seconds

---

## ğŸ“ Project Structure

```
book-notes-summarizer/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ generate/route.ts     # Main pipeline: normalize â†’ RAG â†’ generate â†’ validate â†’ repair
â”‚   â”‚   â”œâ”€â”€ embeddings/route.ts   # RAG retrieval endpoint
â”‚   â”‚   â”œâ”€â”€ evaluate/route.ts     # Faithfulness scoring (embedding similarity)
â”‚   â”‚   â””â”€â”€ health/route.ts       # API key health check
â”‚   â”œâ”€â”€ globals.css               # Dark theme, custom fonts, animations
â”‚   â”œâ”€â”€ layout.tsx
â”‚   â””â”€â”€ page.tsx                  # Main app orchestration
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ ui/                       # Button, Tabs, Dialog (shadcn-style)
â”‚   â””â”€â”€ app/
â”‚       â”œâ”€â”€ NotesPanel.tsx        # Text input with sample loader
â”‚       â”œâ”€â”€ ModeSelector.tsx      # 4-mode tabs with completion indicators
â”‚       â”œâ”€â”€ HighlightsDrawer.tsx  # Collapsible parsed highlights list
â”‚       â”œâ”€â”€ OutputPanel.tsx       # Results with citations, metrics, export
â”‚       â”œâ”€â”€ ExportMenu.tsx        # Markdown, Notion, JSON, plain text
â”‚       â”œâ”€â”€ ComparisonView.tsx    # Side-by-side 4-mode comparison
â”‚       â”œâ”€â”€ EvalDashboard.tsx     # Run stats, pass rates, failure analysis
â”‚       â”œâ”€â”€ NoteSetManager.tsx    # Save/load/delete note sets
â”‚       â”œâ”€â”€ StrictnessToggle.tsx  # Strict vs Balanced mode
â”‚       â””â”€â”€ ApiStatus.tsx         # Groq connection status banner
â”œâ”€â”€ lib/
â”‚   â”œâ”€â”€ schema.ts                 # Zod schemas, validators, metrics
â”‚   â”œâ”€â”€ prompts.ts                # System, user, repair prompts (strictness-aware)
â”‚   â”œâ”€â”€ groq.ts                   # Groq API client
â”‚   â”œâ”€â”€ embeddings.ts             # HuggingFace embeddings + fallback
â”‚   â”œâ”€â”€ retrieval.ts              # RAG: query plans, top-k retrieval
â”‚   â”œâ”€â”€ storage.ts                # localStorage persistence
â”‚   â”œâ”€â”€ normalizer.ts             # Raw text â†’ Highlight[]
â”‚   â””â”€â”€ utils.ts                  # Helpers, markdown export
â””â”€â”€ __tests__/
    â”œâ”€â”€ schema.test.ts            # 30+ validator tests
    â””â”€â”€ phase45.test.ts           # RAG + embedding tests
```

---

## ğŸ”’ How Grounding Works

```
Raw Notes
    â†“
Normalize â†’ [H1] [H2] [H3] â€¦ [Hn]
    â†“
RAG Retrieval (mode-specific queries â†’ top-k highlights)
    â†“
Groq (Llama 3.3 70B) generates JSON
    â†“
Zod validates against mode schema
    â†“ fail?
Repair prompt (1 retry with error feedback)
    â†“
Citation check (all cited IDs must exist)
    â†“
Return validated output + metrics
```

---

## ğŸ§ª Testing

30+ unit tests covering all validators, normalizer, citation checker, metrics, and embeddings.

```
âœ“ oneMinute â€” word limit (120), item count (3â€“5), citations
âœ“ technical â€” word limit (250), item count (4â€“8)
âœ“ interview â€” exactly 5 bullets, â‰¤18 words each
âœ“ kidFriendly â€” word limit (120), analogy required, item count (2â€“4)
âœ“ citations â€” valid/missing ID detection, deduplication
âœ“ metrics â€” word count, coverage, schema pass
âœ“ cosine similarity â€” identical, orthogonal, opposite vectors
âœ“ support field â€” direct/inferred tagging
```

---

## ğŸ’° Cost: $0

| Service | Free Tier |
|---|---|
| **Groq** | 30 req/min, 1000 req/day, never charged |
| **HuggingFace** | Rate-limited embeddings, no cost |
| **Vercel** | 100GB bandwidth, serverless functions |
| **Total** | **$0/month** |

---

## ğŸ›  Tech Stack

- **Framework**: Next.js 14 (App Router) + TypeScript
- **Styling**: TailwindCSS + shadcn/ui + Radix primitives
- **AI Generation**: Groq (Llama 3.3 70B) â€” free, 30 RPM
- **Embeddings**: HuggingFace Inference (sentence-transformers/all-MiniLM-L6-v2)
- **Validation**: Zod with per-mode schemas + auto-repair
- **Persistence**: localStorage (client-side)
- **Testing**: Vitest
- **Deployment**: Vercel

---

## License

MIT
